{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:06.210046Z",
     "start_time": "2024-04-04T22:10:06.206796Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c1471b7a336aabf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:18:25.479817Z",
     "start_time": "2024-04-04T22:18:25.471286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the 10x10 grid map\n",
    "# note that (0,0) is in the bottom-left corner\n",
    "# the map is stored as a 1D list\n",
    "# the cell (x,y) is indexed as [x+y*10] for x in [0,9] and y in [0,9]\n",
    "# x is the horizontal axis, y is the vertical axis\n",
    "# so the index looks like: \n",
    "#\n",
    "# 90 91 92 93 94 95 96 97 98 99\n",
    "# 80 81 82 83 84 85 86 87 88 89\n",
    "# ...\n",
    "# 10 11 12 13 14 15 16 17 18 19\n",
    "# 00 01 02 03 04 05 06 07 08 09\n",
    "#\n",
    "# each element is a number storing the reward for ending up in that cell\n",
    "\n",
    "# Create the map\n",
    "state_reward_map = -np.ones(10 ** 2, dtype=int)\n",
    "\n",
    "# Abot special grids: \n",
    "# If the agent enters an obstacle cell, it will always stay there, won't be able to move\n",
    "# If the agent enters a goal cell, it will always stay and receive the goal state reward at every time step\n",
    "\n",
    "# Define the rewards of special grids\n",
    "# The obstacle cells are [[9, 9], [8, 9], [7, 9], [6, 9], [5, 9], [4, 9], [3, 9], [2, 9], [1, 9], [0, 9],\n",
    "# [9, 8], [9, 7], [9, 6], [9, 5], [9, 4], [9, 3], [9, 2], [9, 1], [9, 0],\n",
    "# [0, 0], [1, 0], [2, 0], [3, 0], [4, 0], [5, 0], [6, 0], [7, 0], [8, 0], [9, 0],\n",
    "# [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9],\n",
    "# [3, 2], [4, 2], [5, 2], [6, 2],\n",
    "# [4, 4], [4, 5], [4, 6], [4, 7], [5, 7],\n",
    "# [7, 4], [7, 5]]\n",
    "# Ending up in an obstacle cell receives a reward of -10 every time step\n",
    "obstacle_coords = [[9, 9], [8, 9], [7, 9], [6, 9], [5, 9], [4, 9], [3, 9], [2, 9], [1, 9], [0, 9],\n",
    "                  [9, 8], [9, 7], [9, 6], [9, 5], [9, 4], [9, 3], [9, 2], [9, 1], [9, 0],\n",
    "                  [0, 0], [1, 0], [2, 0], [3, 0], [4, 0], [5, 0], [6, 0], [7, 0], [8, 0], [9, 0],\n",
    "                  [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9],\n",
    "                  [3, 2], [4, 2], [5, 2], [6, 2],\n",
    "                  [4, 4], [4, 5], [4, 6], [4, 7], [5, 7],\n",
    "                  [7, 4], [7, 5]]\n",
    "for cell in obstacle_coords:\n",
    "    state_reward_map[cell[0] + cell[1] * 10] = -10\n",
    "\n",
    "# Define the goal cells\n",
    "goal_coords = [[8, 1]]\n",
    "# Ending up in a goal cell receives a reward of 10 every time step\n",
    "for cell in goal_coords:\n",
    "    state_reward_map[cell[0] + cell[1] * 10] = 10\n",
    "    \n",
    "# Define the origin cells\n",
    "origin_1_coords = [[1, 1]]\n",
    "origin_2_coords = [[3, 6]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8953bdf4d511e4d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:18:27.128001Z",
     "start_time": "2024-04-04T22:18:26.972529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward map:\n",
      "[-10 -10 -10 -10 -10 -10 -10 -10 -10 -10]\n",
      "[-10  -1  -1  -1  -1  -1  -1  -1  10 -10]\n",
      "[-10  -1  -1 -10 -10 -10 -10  -1  -1 -10]\n",
      "[-10  -1  -1  -1  -1  -1  -1  -1  -1 -10]\n",
      "[-10  -1  -1  -1 -10  -1  -1 -10  -1 -10]\n",
      "[-10  -1  -1  -1 -10  -1  -1 -10  -1 -10]\n",
      "[-10  -1  -1  -1 -10  -1  -1  -1  -1 -10]\n",
      "[-10  -1  -1  -1 -10 -10  -1  -1  -1 -10]\n",
      "[-10  -1  -1  -1  -1  -1  -1  -1  -1 -10]\n",
      "[-10 -10 -10 -10 -10 -10 -10 -10 -10 -10]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 500x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the reward map\n",
    "print(\"The reward map:\")\n",
    "for i in range(10):\n",
    "    print(state_reward_map[i*10:i*10+10])\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(state_reward_map.reshape(10, 10), cmap='cividis', origin='lower')\n",
    "plt.colorbar()\n",
    "plt.title('The reward map')\n",
    "plt.show()\n",
    "\n",
    "# We can see that the map is stored upside down, the origin is in the bottom-left corner\n",
    "# But when displaying, we can just set the origin to 'lower' to display it correctly\n",
    "# So there is no need to manually flip the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2117d0fb60ddb46c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:18:46.495797Z",
     "start_time": "2024-04-04T22:18:46.481009Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_x_y_to_state(x, y):\n",
    "    return x + y * 10\n",
    "\n",
    "\n",
    "# def flat_map_to_2D_map(flat_map):\n",
    "#     \"\"\"\n",
    "#     Be very careful that the indexes are formulated like this\n",
    "#         [[90 91 92 93 94 95 96 97 98 99],\n",
    "#          [80 81 82 83 84 85 86 87 88 89],\n",
    "#          ...\n",
    "#          [10 11 12 13 14 15 16 17 18 19],\n",
    "#          [00 01 02 03 04 05 06 07 08 09]]\n",
    "#     \n",
    "#     :param flat_map: (100,) or (100,1) array\n",
    "#     :return: 2D array (10,10), for plotting\n",
    "#     \"\"\"\n",
    "#     # Check if the input is a 2D array, reshape to (100,) if necessary\n",
    "#     if len(flat_map.shape) == 2:\n",
    "#         flat_map = flat_map.reshape(-1)\n",
    "#         \n",
    "#     # Convert the flat map to a 2D map\n",
    "#     map_2d = np.zeros((10, 10))\n",
    "#     for i in range(10):\n",
    "#         for j in range(10):\n",
    "#             map_2d[j, i] = flat_map[i + j * 10]\n",
    "#     return map_2d   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "192ffe20ac8515b1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:22:02.729854Z",
     "start_time": "2024-04-04T22:22:02.711723Z"
    }
   },
   "outputs": [],
   "source": [
    "test_flag = False\n",
    "\n",
    "if test_flag:\n",
    "    # Test flat_map_to_2D_map\n",
    "    # Try creating a map with the obstacles and the goal represented in 1D index\n",
    "    # We can first convert the above defined coordinates to 1D index\n",
    "    obstacle_coords_1D = [map_x_y_to_state(cell[0], cell[1]) for cell in obstacle_coords]\n",
    "    goal_coords_1D = [map_x_y_to_state(cell[0], cell[1]) for cell in goal_coords]\n",
    "    origin_1_coords_1D = [map_x_y_to_state(cell[0], cell[1]) for cell in origin_1_coords]\n",
    "    origin_2_coords_1D = [map_x_y_to_state(cell[0], cell[1]) for cell in origin_2_coords]\n",
    "    \n",
    "    # Mark the obstacles, goal, and origin cells\n",
    "    state_reward_map_1D_test = np.zeros(100)\n",
    "    for cell in obstacle_coords_1D:\n",
    "        state_reward_map_1D_test[cell] = -10\n",
    "    for cell in goal_coords_1D:\n",
    "        state_reward_map_1D_test[cell] = 10\n",
    "    for cell in origin_1_coords_1D:\n",
    "        state_reward_map_1D_test[cell] = 5\n",
    "    for cell in origin_2_coords_1D:\n",
    "        state_reward_map_1D_test[cell] = -5\n",
    "        \n",
    "    map_2d = state_reward_map_1D_test.reshape(10, 10)\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(map_2d, cmap='cividis', origin='lower')\n",
    "    plt.colorbar()\n",
    "    plt.title('Obs, goal, and origins highlighted')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5286e60edf21570b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:19:52.798342Z",
     "start_time": "2024-04-04T22:19:52.788698Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the action list\n",
    "actions = {'stay': -1, 'N': 0, 'E': 1, 'S': 2, 'W': 3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "603a3d9d6a0c696e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:22:04.547362Z",
     "start_time": "2024-04-04T22:22:04.529176Z"
    }
   },
   "outputs": [],
   "source": [
    "# About the action rewards: \n",
    "# The robot is allowed to stay in the goal state indefinitely, and this stay action gets no reward/cost\n",
    "# When in obstacle cells, the robot is forced to stay with receiving reward -10, but no additional action cost\n",
    "# Taking actions at all other states (including stay), regardless of the outcome, receives a reward of -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e278a1169d15ae4f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:06.651634Z",
     "start_time": "2024-04-04T22:10:06.637887Z"
    }
   },
   "outputs": [],
   "source": [
    "# About the action probabilities: \n",
    "# The agent moves in the intended direction with probability 0.7\n",
    "# The agent moves in the left/right of the intended direction with probability 0.1\n",
    "# The agent stays in the same cell with probability 0.1\n",
    "# The agent won't move to the opposite direction of the intended direction\n",
    "\n",
    "# Define a function to always make the policy matrix valid\n",
    "def make_policy_valid(policy):\n",
    "    \"\"\"\n",
    "    Make the policy matrix valid\n",
    "    :param policy: a 10x10 matrix, each element is an action, the action given by the policy only depend on the state (grid)\n",
    "    :return: a valid policy matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the policy matrix is 10x10\n",
    "    if policy.shape != (10, 10): raise ValueError('The policy matrix should be a 10x10 matrix')\n",
    "    # Each element should be an integer in [-1, 3]\n",
    "    if not np.all(np.isin(policy, [-1, 0, 1, 2, 3])): raise ValueError('Each element in the policy matrix should be an integer in [-1, 3]')\n",
    "    # Obstacle cells and goal cells should have no action\n",
    "    obstacle_coords = [[9, 9], [8, 9], [7, 9], [6, 9], [5, 9], [4, 9], [3, 9], [2, 9], [1, 9], [0, 9], [9, 8], [9, 7], [9, 6], [9, 5], [9, 4], [9, 3], [9, 2], [9, 1], [9, 0], [0, 0], [1, 0], [2, 0], [3, 0], [4, 0], [5, 0], [6, 0], [7, 0], [8, 0], [9, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [3, 2], [4, 2], [5, 2], [6, 2], [4, 4], [4, 5], [4, 6], [4, 7], [5, 7], [7, 4], [7, 5]]\n",
    "    goal_coords = [[8, 1]]\n",
    "    for cell in obstacle_coords + goal_coords:\n",
    "        policy[cell[1], cell[0]] = -1\n",
    "        \n",
    "    return policy\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b770d8421ed1ac2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:06.667343Z",
     "start_time": "2024-04-04T22:10:06.653782Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the transition matrix\n",
    "# The transition matrix is a 100x100 matrix\n",
    "# Each row corresponds to a state\n",
    "# Each column corresponds to a possible next state\n",
    "# The element at [row, column] is the probability of transitioning from state \"row\" to state \"column\" with the intended action\n",
    "# The transition matrix is sparse (mostly zeros)\n",
    "\n",
    "# Compute the transition matrix depending on the policy\n",
    "def get_transition_matrix_old(policy):\n",
    "    \"\"\"\n",
    "    Compute the transition matrix depending on the policy\n",
    "    :param policy: a 10x10 matrix, each element is an action, the action given by the policy only depend on the state (grid)\n",
    "    :return: transition matrix, a 100x100 matrix, each element is the probability of transitioning from state \"row\" to state \"column\" with the intended action\n",
    "    \"\"\"\n",
    "    \n",
    "    # # Check if the policy matrix is valid: \n",
    "    # # 10x10\n",
    "    # if policy.shape != (10, 10):\n",
    "    #     raise ValueError('The policy matrix should be a 10x10 matrix')\n",
    "    # # Each element should be an integer in [-1, 3]\n",
    "    # if not np.all(np.isin(policy, [-1, 0, 1, 2, 3])):\n",
    "    #     raise ValueError('Each element in the policy matrix should be an integer in [-1, 3]')\n",
    "    # # Obstacle cells and goal cells should have no action\n",
    "    # obstacle_coords = [[9, 9], [8, 9], [7, 9], [6, 9], [5, 9], [4, 9], [3, 9], [2, 9], [1, 9], [0, 9], [9, 8], [9, 7], [9, 6], [9, 5], [9, 4], [9, 3], [9, 2], [9, 1], [9, 0], [0, 0], [1, 0], [2, 0], [3, 0], [4, 0], [5, 0], [6, 0], [7, 0], [8, 0], [9, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [3, 2], [4, 2], [5, 2], [6, 2], [4, 4], [4, 5], [4, 6], [4, 7], [5, 7], [7, 4], [7, 5]]\n",
    "    # goal_coords = [[8, 1]]\n",
    "    # for cell in obstacle_coords + goal_coords:\n",
    "    #     if policy[cell[1], cell[0]] != -1:\n",
    "    #         raise ValueError('Obstacle cells and goal cells should have no action')\n",
    "            \n",
    "    # Initialize the transition matrix\n",
    "    transition_matrix = np.zeros((100, 100))\n",
    "    \n",
    "    # Fill up the transition matrix\n",
    "    for y in range(10):\n",
    "        for x in range(10):\n",
    "            current_state = x + y * 10\n",
    "            \n",
    "            # Check if current state is an obstacle or goal, then skip further calculations\n",
    "            if state_reward_map[current_state] == -10 or state_reward_map[current_state] == 10:\n",
    "                transition_matrix[current_state, current_state] = 1\n",
    "                continue\n",
    "            \n",
    "            # Map policy action to movement\n",
    "            action = policy[x, y]\n",
    "            directions = [(0, 1), (1, 0), (0, -1), (-1, 0), (0, 0)]  # N, E, S, W, and stay\n",
    "            action_probs = [0.7, 0.1, 0.1, 0.1]  # Probabilities for N, E, S, W, and stay\n",
    "            \n",
    "            for i, (dx, dy) in enumerate(directions):\n",
    "                if i == action:  # Intended direction\n",
    "                    prob = action_probs[0]\n",
    "                elif i == 4:  # Stay\n",
    "                    prob = action_probs[3]\n",
    "                else:  # Side directions\n",
    "                    prob = action_probs[1]\n",
    "\n",
    "                new_x, new_y = x + dx, y + dy\n",
    "                # Check for border crossing\n",
    "                if 0 <= new_x < 10 and 0 <= new_y < 10:\n",
    "                    new_state = new_x + new_y * 10\n",
    "                    transition_matrix[current_state, new_state] += prob\n",
    "                else:  # Add the probability to stay in the current state if moving out of bounds\n",
    "                    transition_matrix[current_state, current_state] += prob\n",
    "\n",
    "    return transition_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12dff71a743fa636",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:06.698536Z",
     "start_time": "2024-04-04T22:10:06.669616Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_transition_matrix(policy, replacement=True):\n",
    "    \"\"\"\n",
    "    :param replacement: True uses the new function, otherwise uses the old function to compute the transition matrix\n",
    "    :param policy: (10,10) matrix, each element is an integer from -1 to 3, representing the action to take\n",
    "    :return: (100,100) matrix, representing the probability of moving from state i to state j\n",
    "\n",
    "    state i is at [i//10, i%10]\n",
    "    \"\"\"\n",
    "    # Check if the policy matrix is valid: \n",
    "    # 10x10\n",
    "    if policy.shape != (10, 10):\n",
    "        raise ValueError('The policy matrix should be a 10x10 matrix')\n",
    "    # Each element should be an integer in [-1, 3]\n",
    "    if not np.all(np.isin(policy, [-1, 0, 1, 2, 3])):\n",
    "        raise ValueError('Each element in the policy matrix should be an integer in [-1, 3]')\n",
    "    # Obstacle cells and goal cells should have no action\n",
    "    obstacle_coords = [[9, 9], [8, 9], [7, 9], [6, 9], [5, 9], [4, 9], [3, 9], [2, 9], [1, 9], [0, 9], [9, 8], [9, 7], [9, 6], [9, 5], [9, 4], [9, 3], [9, 2], [9, 1], [9, 0], [0, 0], [1, 0], [2, 0], [3, 0], [4, 0], [5, 0], [6, 0], [7, 0], [8, 0], [9, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [3, 2], [4, 2], [5, 2], [6, 2], [4, 4], [4, 5], [4, 6], [4, 7], [5, 7], [7, 4], [7, 5]]\n",
    "    goal_coords = [[8, 1]]\n",
    "    for cell in obstacle_coords + goal_coords:\n",
    "        if policy[cell[1], cell[0]] != -1:\n",
    "            raise ValueError('Obstacle cells and goal cells should have no action')\n",
    "    \n",
    "    if replacement is True:\n",
    "    \n",
    "        grid_len = 10\n",
    "        move_prob = 0.7\n",
    "        move_p1_prob = 0.1\n",
    "        move_m1_prob = 0.1\n",
    "        stay_prob = 0.1\n",
    "        \n",
    "        T = np.zeros((grid_len ** 2, grid_len ** 2), dtype=float)\n",
    "        for i in range(grid_len):  # x\n",
    "            for j in range(grid_len):  # y\n",
    "                state = map_x_y_to_state(i, j)  # state = i*10+j, at (i,j)\n",
    "                policy_action = policy[i, j]  # action to take at (i,j) according to policy\n",
    "                if policy_action == 0:  # intend to move N\n",
    "                    # (i,j+1) with prob move_prob if not hit N boundary\n",
    "                    # (i+1,j) with prob move_p1_prob if not hit E boundary\n",
    "                    # (i-1,j) with prob move_m1_prob if not hit W boundary\n",
    "                    # (i,j) with prob stay_prob (not hit any boundary), or stay_prob+move_prob (hit N boundary), or stay_prob+move_p1_prob (hit E boundary), or stay_prob+move_m1_prob (hit W boundary)\n",
    "                    if j < grid_len - 1:\n",
    "                        T[state, map_x_y_to_state(i, j + 1)] += move_prob\n",
    "                    else:\n",
    "                        T[state, state] += move_prob\n",
    "                    if i < grid_len - 1:\n",
    "                        T[state, map_x_y_to_state(i + 1, j)] += move_p1_prob\n",
    "                    else:\n",
    "                        T[state, state] += move_p1_prob\n",
    "                    if i > 0:\n",
    "                        T[state, map_x_y_to_state(i - 1, j)] += move_m1_prob\n",
    "                    else:\n",
    "                        T[state, state] += move_m1_prob\n",
    "                    T[state, state] += stay_prob\n",
    "    \n",
    "                elif policy_action == 1:  # intend to move E\n",
    "                    # (i+1,j) with prob move_prob if not hit E boundary\n",
    "                    # (i,j-1) with prob move_p1_prob if not hit S boundary\n",
    "                    # (i,j+1) with prob move_m1_prob if not hit N boundary\n",
    "                    # (i,j) with prob stay_prob (not hit any boundary), or stay_prob+move_prob (hit E boundary), or stay_prob+move_p1_prob (hit S boundary), or stay_prob+move_m1_prob (hit N boundary)\n",
    "                    if i < grid_len - 1:\n",
    "                        T[state, map_x_y_to_state(i + 1, j)] += move_prob\n",
    "                    else:\n",
    "                        T[state, state] += move_prob\n",
    "                    if j > 0:\n",
    "                        T[state, map_x_y_to_state(i, j - 1)] += move_p1_prob\n",
    "                    else:\n",
    "                        T[state, state] += move_p1_prob\n",
    "                    if j < grid_len - 1:\n",
    "                        T[state, map_x_y_to_state(i, j + 1)] += move_m1_prob\n",
    "                    else:\n",
    "                        T[state, state] += move_m1_prob\n",
    "                    T[state, state] += stay_prob\n",
    "    \n",
    "                elif policy_action == 2:  # intend to move S\n",
    "                    # (i,j-1) with prob move_prob if not hit S boundary\n",
    "                    # (i-1,j) with prob move_p1_prob if not hit W boundary\n",
    "                    # (i+1,j) with prob move_m1_prob if not hit E boundary\n",
    "                    # (i,j) with prob stay_prob (not hit any boundary), or stay_prob+move_prob (hit S boundary), or stay_prob+move_p1_prob (hit W boundary), or stay_prob+move_m1_prob (hit E boundary)\n",
    "                    if j > 0:\n",
    "                        T[state, map_x_y_to_state(i, j - 1)] += move_prob\n",
    "                    else:\n",
    "                        T[state, state] += move_prob\n",
    "                    if i > 0:\n",
    "                        T[state, map_x_y_to_state(i - 1, j)] += move_p1_prob\n",
    "                    else:\n",
    "                        T[state, state] += move_p1_prob\n",
    "                    if i < grid_len - 1:\n",
    "                        T[state, map_x_y_to_state(i + 1, j)] += move_m1_prob\n",
    "                    else:\n",
    "                        T[state, state] += move_m1_prob\n",
    "                    T[state, state] += stay_prob\n",
    "    \n",
    "                elif policy_action == 3:  # intend to move W\n",
    "                    # (i-1,j) with prob move_prob if not hit W boundary\n",
    "                    # (i,j+1) with prob move_p1_prob if not hit N boundary\n",
    "                    # (i,j-1) with prob move_m1_prob if not hit S boundary\n",
    "                    # (i,j) with prob stay_prob (not hit any boundary), or stay_prob+move_prob (hit W boundary), or stay_prob+move_p1_prob (hit N boundary), or stay_prob+move_m1_prob (hit S boundary)\n",
    "                    if i > 0:\n",
    "                        T[state, map_x_y_to_state(i - 1, j)] += move_prob\n",
    "                    else:\n",
    "                        T[state, state] += move_prob\n",
    "                    if j < grid_len - 1:\n",
    "                        T[state, map_x_y_to_state(i, j + 1)] += move_p1_prob\n",
    "                    else:\n",
    "                        T[state, state] += move_p1_prob\n",
    "                    if j > 0:\n",
    "                        T[state, map_x_y_to_state(i, j - 1)] += move_m1_prob\n",
    "                    else:\n",
    "                        T[state, state] += move_m1_prob\n",
    "                    T[state, state] += stay_prob\n",
    "    \n",
    "                else:  # -1 and otherwise, intend to stay\n",
    "                    # (i,j) with prob stay_prob\n",
    "                    T[state, state] += 1\n",
    "    \n",
    "        return T\n",
    "    else:\n",
    "        return get_transition_matrix_old(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c4df2bc54175b20",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:06.713530Z",
     "start_time": "2024-04-04T22:10:06.699760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1  1  1  1  1  1  1  1 -1 -1]\n",
      " [-1  1  1 -1 -1 -1 -1  1  1 -1]\n",
      " [-1  1  1  1  1  1  1  1  1 -1]\n",
      " [-1  1  1  1 -1  1  1 -1  1 -1]\n",
      " [-1  1  1  1 -1  1  1 -1  1 -1]\n",
      " [-1  1  1  1 -1  1  1  1  1 -1]\n",
      " [-1  1  1  1 -1 -1  1  1  1 -1]\n",
      " [-1  1  1  1  1  1  1  1  1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "1\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Test get_transition_matrix\n",
    "# Initialize the policy where the agent always moves W, i.e., policy[x, y] = 1 for all non-obstacle/goal cells\n",
    "policy = 1 * np.ones((10, 10), dtype=int)\n",
    "policy = make_policy_valid(policy)\n",
    "print(policy)\n",
    "print(policy[3,4])\n",
    "transition_matrix = get_transition_matrix(policy, True)\n",
    "print(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6aa57847f23cf54",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:06.729225Z",
     "start_time": "2024-04-04T22:10:06.715687Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_action_cost_map():\n",
    "    \"\"\"\n",
    "    :return: (100,100) matrix, representing the cost of moving from state i to state j, same dimension as the transition matrix\n",
    "    \n",
    "    State i is at [i//10, i%10]\n",
    "    If i is an obstacle, it costs an action cost of 0 to move to itself, it also costs a state cost of 10 to stay in the obstacle, but this is not considered in the action cost\n",
    "    If i is a goal, it also costs an action cost of 0 to move to itself, it receives a state reward of 10 to stay in the goal, but this is not considered in the action cost/reward\n",
    "    All other moves cost an action cost of 1, regardless of whether the move is successful or not, or the end-up-state is an obstacle or goal\n",
    "    \n",
    "    Note that in this function, all cost are positive, rewards are negative\n",
    "    When using this function, the cost matrix should be negated to get the reward matrix\n",
    "    \"\"\"\n",
    "    grid_len = 10\n",
    "    action_cost = np.ones((grid_len ** 2, grid_len ** 2), dtype=float)\n",
    "    for i in range(grid_len):  # x\n",
    "        for j in range(grid_len):  # y\n",
    "            if [i, j] in obstacle_coords:  # obstacle, cost 0 to move to itself, cannot move to other states\n",
    "                state = map_x_y_to_state(i, j)\n",
    "                action_cost[state, :] = 100  # set all costs to 1000, cannot move to other states\n",
    "                action_cost[state, state] = 0\n",
    "            elif [i, j] in goal_coords:  # goal, cost 0 to move to itself, cannot move to other states\n",
    "                state = map_x_y_to_state(i, j)\n",
    "                action_cost[state, :] = 100  # set all costs to 1000, cannot move to other states\n",
    "                action_cost[state, state] = 0\n",
    "            else:  # other states, cost 1 to move to other states\n",
    "                # since we initialize the action cost to 1, we don't need to do anything here\n",
    "                pass\n",
    "    return action_cost * 0  # No longer needed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68a1b284b9f4e67a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:06.745341Z",
     "start_time": "2024-04-04T22:10:06.730406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0. 100. 100. ... 100. 100. 100.]\n",
      " [100.   0. 100. ... 100. 100. 100.]\n",
      " [100. 100.   0. ... 100. 100. 100.]\n",
      " ...\n",
      " [100. 100. 100. ...   0. 100. 100.]\n",
      " [100. 100. 100. ... 100.   0. 100.]\n",
      " [100. 100. 100. ... 100. 100.   0.]]\n"
     ]
    }
   ],
   "source": [
    "# Test get_action_cost\n",
    "action_cost_map = get_action_cost_map()\n",
    "print(action_cost_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0e473f9fe72b0c2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:06.761272Z",
     "start_time": "2024-04-04T22:10:06.746370Z"
    }
   },
   "outputs": [],
   "source": [
    "def policy_evaluation(policy, transition_matrix, state_reward_map, action_cost_map, gamma=0.99, theta=1e-4):\n",
    "    \"\"\"\n",
    "    Evaluate a policy given an environment and a full description of the environment's dynamics.\n",
    "    \n",
    "    Args:\n",
    "        policy: [10x10 numpy array] The policy to evaluate, where policy[x, y] gives the action to take at position (x, y).\n",
    "        transition_matrix: [100x100 numpy array] State transition probabilities for each action.\n",
    "        state_reward_map: [numpy array] Immediate rewards for all states.\n",
    "        gamma: float, Discount factor.\n",
    "        theta: float, A threshold of change for the value function to determine convergence.\n",
    "        \n",
    "    Returns:\n",
    "        V: (100,) numpy array, The value for each state under the specified policy.\n",
    "    \"\"\"\n",
    "    V = np.zeros(100)  # Initialize state-value function with zeros for each state\n",
    "    iteration = 0  # Initialize iteration counter\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        delta = 0  # Initialize delta to 0 for this iteration\n",
    "        # For each state, perform a \"full backup\"\n",
    "        for s in range(100):\n",
    "            v = V[s]  # Store the current value of state s\n",
    "            # Get the action recommended by the policy for state s\n",
    "            x, y = s % 10, s // 10  # Convert state index to grid position, s = x + y*10\n",
    "            action = policy[x, y]  # Retrieve action from policy\n",
    "            # Initialize a new value for state s\n",
    "            new_value = 0\n",
    "            # For each possible next state, calculate the contribution to the new value\n",
    "            for s_prime in range(100):\n",
    "                # Action affects transition probability: transition_matrix[action][s, s_prime]\n",
    "                # However, we already generated the transition matrix for current policy\n",
    "                # i.e. we no longer need a complete transition matrix with the [action] index\n",
    "                new_value += transition_matrix[s, s_prime] * (state_reward_map[s_prime] - action_cost_map[s, s_prime] + gamma * V[s_prime])\n",
    "            # Update the value of state s in V\n",
    "            V[s] = new_value\n",
    "            # Calculate the maximum change in value across all states seen so far\n",
    "            delta = max(delta, abs(v - V[s]))\n",
    "        # Check if the change in value function is below the threshold for all states\n",
    "        if delta < theta:\n",
    "            break\n",
    "    print(f'Policy evaluated in {iteration} iterations')\n",
    "    return V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "664dc700469b8131",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:13.144278Z",
     "start_time": "2024-04-04T22:10:06.762299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy evaluated in 1147 iterations\n",
      "-197.993252890784 -1057.3259330912294 -1097.3380931846918\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 500x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test policy_evaluation\n",
    "# Initialize the policy where the agent always moves W, i.e., policy[x, y] = 1 for all non-obstacle/goal cells\n",
    "policy = 1 * np.ones((10, 10), dtype=int)\n",
    "policy = make_policy_valid(policy)\n",
    "transition_matrix = get_transition_matrix(policy)\n",
    "V = policy_evaluation(policy, transition_matrix, state_reward_map, action_cost_map)\n",
    "print(V[map_x_y_to_state(1,3)], V[map_x_y_to_state(3,1)], V[map_x_y_to_state(8,1)])\n",
    "\n",
    "# Convert V to a 10x10 matrix for visualization\n",
    "# Be careful that the origin is in the bottom-left corner\n",
    "V_2D = V.reshape(10, 10)\n",
    "\n",
    "# Visualize the value function\n",
    "# V[map_x_y_to_state(8, 1)] = 100  # Use this to indentify the goal state\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(V_2D, cmap='cividis', origin='lower')\n",
    "plt.colorbar()\n",
    "plt.title('Value function for Given Policy')\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(range(10))\n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50c552cecec06e57",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:13.160116Z",
     "start_time": "2024-04-04T22:10:13.145369Z"
    }
   },
   "outputs": [],
   "source": [
    "def policy_improvement(V, policy, transition_matrix, state_reward_map, action_cost_map, gamma=0.9):\n",
    "    \"\"\"\n",
    "    Improve a policy given the value function.\n",
    "    \n",
    "    Args:\n",
    "        V: [numpy array] The value for each state under the specified policy.\n",
    "        policy: [10x10 numpy array] The policy to evaluate, where policy[x, y] gives the action to take at position (x, y).\n",
    "        transition_matrix: [100x100 numpy array] State transition probabilities for each action.\n",
    "        state_reward_map: [numpy array] Immediate rewards for all states.\n",
    "        gamma: float, Discount factor.\n",
    "        \n",
    "    Returns:\n",
    "        policy: [10x10 numpy array] The improved policy.\n",
    "        policy_stable: [bool] Whether the policy is stable.\n",
    "    \"\"\"\n",
    "    obstacle_coords = [[9, 9], [8, 9], [7, 9], [6, 9], [5, 9], [4, 9], [3, 9], [2, 9], [1, 9], [0, 9],\n",
    "                  [9, 8], [9, 7], [9, 6], [9, 5], [9, 4], [9, 3], [9, 2], [9, 1], [9, 0],\n",
    "                  [0, 0], [1, 0], [2, 0], [3, 0], [4, 0], [5, 0], [6, 0], [7, 0], [8, 0], [9, 0],\n",
    "                  [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9],\n",
    "                  [3, 2], [4, 2], [5, 2], [6, 2],\n",
    "                  [4, 4], [4, 5], [4, 6], [4, 7], [5, 7],\n",
    "                  [7, 4], [7, 5]]\n",
    "    goal_coords = [[8, 1]]\n",
    "    \n",
    "    obstacle_states = [map_x_y_to_state(cell[0], cell[1]) for cell in obstacle_coords]\n",
    "    goal_states = [map_x_y_to_state(cell[0], cell[1]) for cell in goal_coords]    \n",
    "    \n",
    "    policy_stable = True  # Initialize policy_stable to True\n",
    "    for s in range(100):\n",
    "        # Skip the obstacle and goal states\n",
    "        if s in obstacle_states or s in goal_states:\n",
    "            continue\n",
    "        \n",
    "        old_action = policy[s % 10, s // 10]  # Retrieve action from policy at state s (x,y)\n",
    "        # Initialize the best action and value for state s\n",
    "        best_action = None\n",
    "        best_value = float('-inf')\n",
    "        # For each possible action, calculate the value of the state\n",
    "        for action in range(4):\n",
    "            new_value = 0\n",
    "            \n",
    "            # a_kp1(s) = argmax_a expectation[ r(s,a) + gamma * V(s') ]\n",
    "            for s_prime in range(100):\n",
    "                new_value += transition_matrix[s, s_prime] * (state_reward_map[s_prime] - action_cost_map[s, s_prime] + gamma * V[s_prime])\n",
    "            # Update the best action and value if a better action is found\n",
    "            if new_value > best_value:\n",
    "                best_value = new_value\n",
    "                best_action = action\n",
    "            \n",
    "        # Update the policy with the best action for state s (x,y)\n",
    "        policy[s % 10, s // 10] = best_action\n",
    "        # Check if the best action is different from the old action\n",
    "        if best_action != old_action:\n",
    "            policy_stable = False\n",
    "             \n",
    "    return policy, policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5614b16da21f56e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:13.176015Z",
     "start_time": "2024-04-04T22:10:13.161217Z"
    }
   },
   "outputs": [],
   "source": [
    "def policy_iteration(policy, state_reward_map, action_cost_map, gamma=0.9, theta=1e-4, save_for_vis=False, max_iter=50):\n",
    "    \"\"\"\n",
    "    Perform policy iteration to find the optimal policy.\n",
    "    \n",
    "    Args:\n",
    "        policy: [10x10 numpy array] The initial policy to evaluate.\n",
    "        state_reward_map: [numpy array] Immediate rewards for all states.\n",
    "        gamma: float, Discount factor.\n",
    "        theta: float, A threshold of change for the value function to determine convergence.\n",
    "        \n",
    "    Returns:\n",
    "        policy: [10x10 numpy array] The optimal policy.\n",
    "    \"\"\"\n",
    "    policy_stable = False  # Initialize policy_stable to False\n",
    "    \n",
    "    # We want to save the evaluation and improvement results in the first 5 iterations and the last iteration\n",
    "    # This is to visualize the policy improvement process\n",
    "    V_list = []\n",
    "    policy_list = []\n",
    "    iteration = 0\n",
    "    while iteration < max_iter:\n",
    "        iteration += 1\n",
    "        transition_matrix = get_transition_matrix(policy)\n",
    "        V = policy_evaluation(policy, transition_matrix, state_reward_map, action_cost_map, gamma, theta)\n",
    "        policy, policy_stable = policy_improvement(V, policy, transition_matrix, state_reward_map, action_cost_map, gamma)\n",
    "        policy = make_policy_valid(policy)\n",
    "        if iteration <= 5 or policy_stable:\n",
    "            V_list.append(V)\n",
    "            policy_list.append(policy)\n",
    "        if policy_stable:\n",
    "            break\n",
    "            \n",
    "    print(f'Policy iteration converged in {iteration} iterations')\n",
    "    \n",
    "    if save_for_vis:\n",
    "        return policy, policy_stable, V_list, policy_list\n",
    "    else:\n",
    "        return policy, policy_stable\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58b3d17ff9d7af1d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:11:03.756507Z",
     "start_time": "2024-04-04T22:10:33.445292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy evaluated in 111 iterations\n",
      "Policy iteration converged in 50 iterations\n",
      "Converged = False\n",
      "[[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1  0  0  0  0  0  0  0 -1 -1]\n",
      " [-1  0  0 -1 -1 -1 -1  0  0 -1]\n",
      " [-1  0  1  0  0  0  0  0  0 -1]\n",
      " [-1  0  1  0 -1  1  1 -1  0 -1]\n",
      " [-1  0  1  0 -1  0  0 -1  0 -1]\n",
      " [-1  0  1  0 -1  0  0  0  0 -1]\n",
      " [-1  0  0  0 -1 -1  0  0  0 -1]\n",
      " [-1  1  0  0  0  0  0  0  0 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "# Test policy_iteration\n",
    "# Initialize the policy where the agent always moves N, i.e., policy[x, y] = 1 for all non-obstacle/goal cells\n",
    "policy = 1 * np.ones((10, 10), dtype=int)\n",
    "policy = make_policy_valid(policy)\n",
    "transition_matrix = get_transition_matrix(policy)\n",
    "policy, convergence = policy_iteration(policy, state_reward_map, action_cost_map)\n",
    "print(\"Converged =\", convergence)\n",
    "print(policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab933fe09f7cdd6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:13.224281Z",
     "start_time": "2024-04-04T22:10:13.224281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the policy using arrows\n",
    "# The origin is in the bottom-left corner\n",
    "# The arrows are in the same direction as the action\n",
    "# The arrows are in the center of the cell\n",
    "# No arrow is shown for obstacle cells and goal cells\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(V_2D, cmap='cividis', origin='lower')\n",
    "plt.colorbar()\n",
    "plt.title('Optimal Policy')\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(range(10))\n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "# policy[3, 7] = 3  # Use this to see if the policy is correctly visualized at desired coordinates\n",
    "for y in range(10):\n",
    "    for x in range(10):\n",
    "        if [x, y] in obstacle_coords or [x, y] in goal_coords:\n",
    "            continue\n",
    "        if policy[x, y] == 0:  # N\n",
    "            plt.arrow(x, y, 0, 0.4, head_width=0.1, head_length=0.1, fc='r', ec='r')\n",
    "        elif policy[x, y] == 1:  # E\n",
    "            plt.arrow(x, y, 0.4, 0, head_width=0.1, head_length=0.1, fc='r', ec='r')\n",
    "        elif policy[x, y] == 2:  # S\n",
    "            plt.arrow(x, y, 0, -0.4, head_width=0.1, head_length=0.1, fc='r', ec='r')\n",
    "        elif policy[x, y] == 3:  # W\n",
    "            plt.arrow(x, y, -0.4, 0, head_width=0.1, head_length=0.1, fc='r', ec='r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f2b37213aa88",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T22:10:13.225392Z",
     "start_time": "2024-04-04T22:10:13.225392Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
